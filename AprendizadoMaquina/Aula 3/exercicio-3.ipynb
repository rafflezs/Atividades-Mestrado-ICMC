{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CI8fNbys1WIN"
      },
      "source": [
        "# SCC-ICMC-USP - 1o. semestre de 2024\n",
        "# SCC5871/MAI5025 - APRENDIZADO DE MÁQUINA\n",
        "# Exercício 3\n",
        "\n",
        "### Profa. Roseli A. F. Romero\n",
        "\n",
        "\n",
        "Nro do grupo:\n",
        "\n",
        "Alunos:\n",
        "\n",
        "\n",
        "1.   Julyana Flores de Prá\n",
        "2.   Thiago Rafael Mariotti Claudio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIUUyGhs5-p0"
      },
      "source": [
        "## Objetivo: Curva ROC e Teste de hipótese;\n",
        "##           Utilização de Perceptron, MLP, DT e KNN\n",
        "\n",
        "## Funções novas utilizadas no exercício\n",
        "\n",
        "- `pandas.Series.nunique()` ([link](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.nunique.html)): Conta quantidade de valores únicos de uma coluna. Útil para verificar se uma coluna é relevante ou não\n",
        "- `scipy.stats.ttest_ind()` ([link](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html#scipy.stats.ttest_ind)): Calcula o teste t para duas amostras independentes\n",
        "- `sklearn.metrics.plot_roc_curve()` ([link](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_roc_curve.html)): Plota a curva ROC de um classificador dado um conjunto de input e alvo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjxiImds6u9L"
      },
      "source": [
        "### Questão 01.\n",
        "\n",
        "Faça a exploração dos dados. Isto é, carregue, substitua valores faltantes, padronize os dados, etc. Faça também a seleção dos atributos que achar mais relevantes.\n",
        "\n",
        " - Dica: Utilize a função `nunique()` durante a exploração dos dados. Você pode utilizar o \"bom senso\" (além de outras ferramentas é claro) na hora de escolher qual atributo do conjunto manter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTS4V3jN590F"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "df = pd.read_csv(\"train.csv\")\n",
        "\n",
        "df[\"Survived\"] = pd.to_numeric(df[\"Survived\"], errors=\"coerce\")\n",
        "\n",
        "#male = 1, female = 0\n",
        "df['Sex_Encoded'] = label_encoder.fit_transform(df['Sex'])\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSPxl7Q-y4Mz"
      },
      "outputs": [],
      "source": [
        "# Etapas de pré-processamento que podem ser feitas antes de separar em treino/teste vão aqui\n",
        "# código de solução\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mean_age = df['Age'].mean()\n",
        "df['Age'].fillna(mean_age, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "attributes = [\"Pclass\", \"Fare\", \"Survived\", \"Age\", \"Sex_Encoded\", \"SibSp\", \"Parch\"]\n",
        "correlation = df[attributes].corr()\n",
        "correlation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "sns.heatmap(correlation, annot=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9MVpvgX7Z0u"
      },
      "source": [
        "### Questão 02.\n",
        "\n",
        "- a) Separe o conjunto de dados de maneira estratificada (através do parâmetro `stratify` da função `train_test_split`) em 20% para teste e 80% para treino. Depois plote a curva ROC (`sklearn.metrics.plot_roc_curve`) para **todos** os classificadores (no mesmo gráfico).\n",
        "\n",
        "- b) Os melhores classificadores da questão anterior também apresentaram melhor desempenho na curva ROC? O que pode ter ocorrido? Teste diferentes valores de `random_state` na função `train_test_split` e observe o comportamento das curvas.\n",
        "\n",
        "\n",
        "*   Dica: Para plotar múltiplas curvas ROC no mesmo gráfico, defina uma figura com `fig, ax = plt.subplots()` e passe `ax` como parâmetro da função `plot_roc_curve`. Não se esqueça de passar também o nome do classificador para que o seu gráfico fique mais fácil de interpretar\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oPHjrIF__aoa"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Separar conjunto e pré processamento\n",
        "df_novo = df[attributes].copy(deep=True)\n",
        "X = df_novo.drop(columns=['Survived'])  # Supondo que 'Survived' seja o atributo alvo\n",
        "y = df_novo['Survived']\n",
        "\n",
        "# Pré-processamento: padronizar os dados\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0XKyiyeM7WTB"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "\n",
        "classificadores = {\n",
        "  \"Perceptron\" : {\"modelo\": Perceptron(), \"scores\": []},\n",
        "  \"Multi-Layer Perceptron (15,)\" : {\"modelo\": MLPClassifier(random_state=1, hidden_layer_sizes=(15,), max_iter=2000), \"scores\": []},\n",
        "  \"Árvore Decisão Critério Gini\" : {\"modelo\": DecisionTreeClassifier(criterion='gini'), \"scores\": []},\n",
        "  \"KNN k=5\" : {\"modelo\": KNeighborsClassifier(n_neighbors=5), \"scores\": []}\n",
        "}\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "plt.rcParams['figure.figsize'] = [15, 10]\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "for classificador_name, classificador_info in classificadores.items():\n",
        "    clf = classificador_info[\"modelo\"]\n",
        "    \n",
        "    clf.fit(X_train, y_train)\n",
        "    \n",
        "    y_pred = clf.predict(X_test)\n",
        "    \n",
        "    roc_auc = metrics.roc_auc_score(y_test, y_pred)\n",
        "    classificador_info[\"scores\"].append(roc_auc)\n",
        "    \n",
        "    metrics.plot_roc_curve(clf, X_test, y_test, ax=ax, name=classificador_name)\n",
        "\n",
        "plt.title('Curva ROC para todos os classificadores')\n",
        "plt.xlabel('Taxa de Falso Positivo')\n",
        "plt.ylabel('Taxa de Verdadeiro Positivo')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klIBW1XGGez2"
      },
      "source": [
        "### Questão 03.\n",
        "\n",
        "Implemente o 10-Fold Cross Validation (pode usar o scikit) com os dois melhores classificadores de acordo com a curva ROC e guarde a acurácia de cada fold na chave 'scores' do dicionário de classificadores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBpcAFP4IHN0"
      },
      "outputs": [],
      "source": [
        "# Seu código aqui\n",
        "# Lembre-se do pré-processamento\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "melhores_classificadores = sorted(classificadores.items(), key=lambda x: np.mean(x[1][\"scores\"]), reverse=True)[:2]\n",
        "\n",
        "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "for classificador_name, classificador_info in melhores_classificadores:\n",
        "    clf = classificador_info[\"modelo\"]\n",
        "    \n",
        "    scores = cross_val_score(clf, X, y, cv=kf)\n",
        "    \n",
        "    classificador_info[\"scores\"] = scores\n",
        "\n",
        "# Imprimir as acurácias de cada fold para os melhores classificadores\n",
        "for classificador_name, classificador_info in melhores_classificadores:\n",
        "    print(f\"Classificador: {classificador_name}\")\n",
        "    print(f\"Acurácias dos folds: {classificador_info['scores']}\")\n",
        "    print(f\"Acurácia média: {np.mean(classificador_info['scores'])}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzLXd0Qhuf15"
      },
      "source": [
        "### Questão 04.\n",
        "Altere a configuração da rede MLP, da arvore de Decisão (use outra função de entropia, o no. de vizinhos mais proximo no método KNN. Verifique o desempenho de cada um deles e compare com cada caso anterior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "classificadores_modificados = {\n",
        "    \"Perceptron\": {\"modelo\": Perceptron(), \"scores\": []},\n",
        "    \"MLP (20, 10)\": {\"modelo\": MLPClassifier(random_state=1, hidden_layer_sizes=(20, 10), max_iter=2000), \"scores\": []},\n",
        "    \"Árvore Decisão (entropy)\": {\"modelo\": DecisionTreeClassifier(criterion='entropy'), \"scores\": []},\n",
        "    \"KNN k=10\": {\"modelo\": KNeighborsClassifier(n_neighbors=10), \"scores\": []}\n",
        "}\n",
        "\n",
        "for classificador_name, classificador_info in classificadores_modificados.items():\n",
        "    clf = classificador_info[\"modelo\"]\n",
        "    \n",
        "    scores = cross_val_score(clf, X, y, cv=kf)\n",
        "    \n",
        "    classificador_info[\"scores\"] = scores\n",
        "\n",
        "for classificador_name, classificador_info in classificadores_modificados.items():\n",
        "    print(f\"Classificador: {classificador_name}\")\n",
        "    print(f\"Acurácias dos folds: {classificador_info['scores']}\")\n",
        "    print(f\"Acurácia média: {np.mean(classificador_info['scores'])}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q79VU9FK7Qr4"
      },
      "source": [
        "### Questão 05.\n",
        "\n",
        "Verifique se há diferença estatística significante entre suas acurácias da questão anterior utilizando o teste T (`scipy.stats.ttest_ind`). Considere que há diferença significante se p <= 0.05 (rejeita-se a hipótese nula)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWpS4QiH7TqG"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import ttest_ind\n",
        "\n",
        "acuracias_por_classificador = []\n",
        "\n",
        "for classificador_info in classificadores_modificados.values():\n",
        "    acuracias_por_classificador.append(classificador_info[\"scores\"])\n",
        "\n",
        "p_value, _ = ttest_ind(acuracias_por_classificador[0], acuracias_por_classificador[1])\n",
        "\n",
        "# Verificar se o p-valor é menor ou igual a 0.05\n",
        "if p_value <= 0.05:\n",
        "    print(\"Há diferença estatisticamente significativa entre as acurácias.\")\n",
        "else:\n",
        "    print(\"Não há diferença estatisticamente significativa entre as acurácias.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
